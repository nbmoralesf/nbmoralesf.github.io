cheese_sample <- cheese_df %>% slice(1:10)
# Extract details from a cheese's page
get_cheese_details <- function(cheese_url) {
Sys.sleep(1)
cat("Scraping:", cheese_url, "\n")
page <- tryCatch({
res <- GET(cheese_url, user_agent("Mozilla/5.0"))
read_html(res)
}, error = function(e) return(NA))
if (is.na(page)) {
return(tibble(
milk = NA, country = NA, family = NA, type = NA, flavour = NA
))
}
# Extract labels and values from the info section
labels <- page %>%
html_elements(".panel-body p") %>%
html_text2() %>%
tolower()
values <- page %>%
html_elements(".panel-body a") %>%
html_text2()
# Combine labels and values into a named list
info <- setNames(values, labels)
# Return as a tibble row
tibble(
milk = info[["milk"]],
country = info[["country"]],
family = info[["family"]],
type = info[["type"]],
flavour = info[["flavour"]]
)
}
# Apply to the sample of 10 cheeses
cheese_details <- cheese_sample %>%
mutate(detail = map(url, get_cheese_details)) %>%
unnest(detail)
cheese_sample <- cheese_df %>% slice(1:10)
# Extract details from a cheese's page
get_cheese_details <- function(cheese_url) {
Sys.sleep(1)
cat("Scraping:", cheese_url, "\n")
page <- tryCatch({
res <- GET(cheese_url, user_agent("Mozilla/5.0"))
read_html(res)
}, error = function(e) return(NA))
if (is.na(page)) {
return(tibble(
milk = NA, country = NA, family = NA, type = NA, flavour = NA
))
}
# Define a helper function to extract the value next to a known label
extract_value <- function(label) {
node <- html_elements(page, ".panel-body p") %>%
keep(~ str_detect(tolower(html_text2(.x)), label)) %>%
html_element("a") %>%
html_text2()
if (length(node) == 0) return(NA)
return(node)
}
# Extract individual fields
tibble(
milk = extract_value("milk"),
country = extract_value("country"),
family = extract_value("family"),
type = extract_value("type"),
flavour = extract_value("flavour")
)
}
# Apply to the sample of 10 cheeses
cheese_details <- cheese_sample %>%
mutate(detail = map(url, get_cheese_details)) %>%
unnest(detail)
library(rvest)
library(purrr)
library(tidyr)
library(stringr)
cheese_sample <- cheese_df %>% slice(1:10)
# Extract details from a cheese's page
get_cheese_details <- function(cheese_url) {
Sys.sleep(1)
cat("Scraping:", cheese_url, "\n")
page <- tryCatch({
res <- GET(cheese_url, user_agent("Mozilla/5.0"))
read_html(res)
}, error = function(e) return(NA))
if (is.na(page)) {
return(tibble(
milk = NA, country = NA, family = NA, type = NA, flavour = NA
))
}
# Define a helper function to extract the value next to a known label
extract_value <- function(label) {
node <- html_elements(page, ".panel-body p") %>%
keep(~ str_detect(tolower(html_text2(.x)), label)) %>%
html_element("a") %>%
html_text2()
if (length(node) == 0) return(NA)
return(node)
}
# Extract individual fields
tibble(
milk = extract_value("milk"),
country = extract_value("country"),
family = extract_value("family"),
type = extract_value("type"),
flavour = extract_value("flavour")
)
}
# Apply to the sample of 10 cheeses
cheese_details <- cheese_sample %>%
mutate(detail = map(url, get_cheese_details)) %>%
unnest(detail)
# View result
print(cheese_details)
dim(cheese_df)
head(cheese_df)
get_cheeses_from_all_pages <- function(page_num) {
# Build URL
url <- paste0("https://www.cheese.com/alphabetical/?per_page=100&page=", page_num)
# Read HTML with user-agent
res <- GET(url, user_agent("Mozilla/5.0"))
webpage <- read_html(res)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, ".product-item a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
# Return as tibble
tibble(name = cheese_names, url = cheese_urls)
}
# Loop through all 6 pages and bind rows
cheese_df <- map_dfr(1:6, get_cheeses_from_all_pages)
# Preview
print(head(cheese_df))
View(cheese_df)
dim(cheese_df)
head(cheese_df)
get_cheeses_from_all_pages <- function(page_num) {
# Build URL
url <- paste0("https://www.cheese.com/alphabetical/?per_page=100&page=", page_num)
# Read HTML with user-agent
res <- GET(url, user_agent("Mozilla/5.0"))
webpage <- read_html(res)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, ".product-item a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
# Return as tibble
tibble(name = cheese_names, url = cheese_urls)
}
# Loop through all 6 pages and bind rows
cheese_df <- map_dfr(1:6, get_cheeses_from_all_pages)
check_picture <- function(cheese_url) {
Sys.sleep(1)  # Be respectful
cat("Checking:", cheese_url, "\n")
page <- tryCatch({
res <- GET(cheese_url, user_agent("Mozilla/5.0"))
read_html(res)
}, error = function(e) return(NA))
if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- html_element(page, ".image-exists")
!is.na(has_img)
}
# Step 4: Check for images (you can limit for testing)
cheese_df <- cheese_df %>%
mutate(has_picture = map_lgl(url, check_picture))
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)  # Be respectful
cat("Checking:", cheese_url, "\n")
page <- tryCatch({
read_html(cheese_url)
}, error = function(e) return(NA))
if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- html_element(page, ".image-exists")
!is.na(has_img)
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, ".product-item a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
get_cheeses_from_all_pages(paste0(url, 1))
# Preview
head(cheese_df)
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)  # Be respectful
cat("Checking:", cheese_url, "\n")
page <- tryCatch({
read_html(cheese_url)
}, error = function(e) return(NA))
if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- html_element(page, ".image-exists")
!is.na(has_img)
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, ".product-item a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
# Preview
head(page1)
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)  # Be respectful
cat("Checking:", cheese_url, "\n")
page <- tryCatch({
read_html(cheese_url)
}, error = function(e) return(NA))
if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- html_element(page, ".image-exists")
!is.na(has_img)
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, ".product-item a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
# Preview
head(page1)
dim(page1)
webpage <- read_html("https://www.cheese.com/alphabetical/?per_page=100&page=1")
html_elements(webpage, ".product-item a")
html_elements(webpage, "h3 a")
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)  # Be respectful
cat("Checking:", cheese_url, "\n")
page <- tryCatch({
read_html(cheese_url)
}, error = function(e) return(NA))
if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- html_element(page, ".image-exists")
!is.na(has_img)
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, "h3 a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
# Preview
head(page1)
dim(page1)
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)  # Be respectful
cat("Checking:", cheese_url, "\n")
page <- tryCatch({
read_html(cheese_url)
}, error = function(e) return(NA))
if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- html_element(page, ".image-exists")
!is.na(has_img)
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, "h3 a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
cheese_df <- map(paste0(url, 1:21), get_cheeses_from_all_pages) %>%
bind_rows()
# Preview
head(cheese_df)
dim(cheese_df)
webpage
webpage = html("https://www.cheese.com/alphabetical/?per_page=100&page=1")
webpage = read_html("https://www.cheese.com/alphabetical/?per_page=100&page=1")
html_element(webpage, ".image-exists")
html_element(webpage, ".image-missing")
# Use .image-exists to detect picture
has_img <- html_element(page, ".image-exists")
has_img <- html_element(webpage, ".image-exists")
has_img
html_element(webpage, "#main-body img") %>% html_attr("class")
webpage
webpage %>% html_element("#main-body img") %>% html_attr("class")
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- tryCatch({
read_html(cheese_url)
}, error = function(e) return(NA))
if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_element("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, "h3 a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
cheese_df <- map(paste0(url, 1:21), get_cheeses_from_all_pages) %>%
bind_rows()
# Preview
head(cheese_df)
dim(cheese_df)
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_element("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, "h3 a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
cheese_df <- map(paste0(url, 1:21), get_cheeses_from_all_pages) %>%
bind_rows()
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_element("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, "h3 a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
#cheese_df <- map(paste0(url, 1:21), get_cheeses_from_all_pages) %>%
#bind_rows()
# Preview
head(page1)
dim(page1)
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_element("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
check_picture("https://www.cheese.com/alphabetical/?per_page=100&page=1")
check_picture("https://www.cheese.com/alphabetical/?per_page=100&page=2")
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture(url)
html_elements(webpage, "h3 a")
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_elements("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
check_picture(url)
webpage %>% html_elements("#main-body img") %>% html_attr("class")
class(webpage %>% html_elements("#main-body img") %>% html_attr("class"))
# Use .image-exists to detect picture
has_img <- webpage %>% html_elements("#main-body img") %>% html_attr("class")
str_detect(has_img, 'image-exists')
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_elements("#main-body img") %>% html_attr("class")
str_detect(has_img)
}
check_picture(url)
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_elements("#main-body img") %>% html_attr("class")
str_detect(has_img, ".image-exists")
}
check_picture(url)
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_elements("#main-body img") %>% html_attr("class")
image <- str_detect(has_img, ".image-exists")
return(image)
}
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture(url)
