}, error = function(e) return(NA))
if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_element("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, "h3 a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
cheese_df <- map(paste0(url, 1:21), get_cheeses_from_all_pages) %>%
bind_rows()
# Preview
head(cheese_df)
dim(cheese_df)
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_element("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, "h3 a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
cheese_df <- map(paste0(url, 1:21), get_cheeses_from_all_pages) %>%
bind_rows()
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_element("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
get_cheeses_from_all_pages <- function(url) {
# Read HTML with user-agent
webpage <- read_html(url)
# Get cheese names and URLs
cheese_nodes <- html_elements(webpage, "h3 a")
cheese_names <- html_text2(cheese_nodes)
cheese_urls <- paste0("https://www.cheese.com", html_attr(cheese_nodes, "href"))
#Check for picture
pic <- check_picture(url)
# Return as tibble
tibble(name = cheese_names, url = cheese_urls, picture = pic)
}
page1 <- get_cheeses_from_all_pages(paste0(url, 1))
#cheese_df <- map(paste0(url, 1:21), get_cheeses_from_all_pages) %>%
#bind_rows()
# Preview
head(page1)
dim(page1)
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_element("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
check_picture("https://www.cheese.com/alphabetical/?per_page=100&page=1")
check_picture("https://www.cheese.com/alphabetical/?per_page=100&page=2")
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture(url)
html_elements(webpage, "h3 a")
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_elements("#main-body img") %>% html_attr("class")
if(has_img == ".image-exists") {
return(TRUE)
}else{
return(FALSE)
}
}
check_picture(url)
webpage %>% html_elements("#main-body img") %>% html_attr("class")
class(webpage %>% html_elements("#main-body img") %>% html_attr("class"))
# Use .image-exists to detect picture
has_img <- webpage %>% html_elements("#main-body img") %>% html_attr("class")
str_detect(has_img, 'image-exists')
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_elements("#main-body img") %>% html_attr("class")
str_detect(has_img)
}
check_picture(url)
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_elements("#main-body img") %>% html_attr("class")
str_detect(has_img, ".image-exists")
}
check_picture(url)
check_picture <- function(cheese_url) {
Sys.sleep(1)
cat("Checking:", cheese_url, "\n")
page <- read_html(cheese_url)
# page <- tryCatch({
#   read_html(cheese_url)
# }, error = function(e) return(NA))
#
# if (is.na(page)) return(FALSE)
# Use .image-exists to detect picture
has_img <- page %>% html_elements("#main-body img") %>% html_attr("class")
image <- str_detect(has_img, ".image-exists")
return(image)
}
url <- "https://www.cheese.com/alphabetical/?per_page=100&page="
check_picture(url)
# Code for loading packages and reading in data
library(tidyverse)
library(egg)
library(ggpubr)
library(gridExtra)
library(patchwork)
month_CulmPrec <- weather %>%
group_by(Month) %>%
filter(Day == max(Day)) %>%
ungroup()
weather <- read_csv("https://mac-stat.github.io/data/sfo_weather.csv")
month_CulmPrec <- weather %>%
group_by(Month) %>%
filter(Day == max(Day)) %>%
ungroup()
last_days <- weather %>%
group_by(Month) %>%
filter(Day == max(Day))
# Code for recreating the visualization
# Use as many code chunks as you need to organize your work well
temp <- weather %>%
ggplot() +
geom_linerange(aes(x = dateInYear, ymax = RecordHigh, ymin = RecordLow), color = "#ECEBE3") +
geom_linerange(aes(x = dateInYear, ymax = NormalHigh, ymin = NormalLow), color = "#C8B8BA") +
geom_rect(aes(xmin = dateInYear - 0.5, xmax = dateInYear + 0.5, ymax = High, ymin = Low), color = "#A90248") +
geom_vline(xintercept = last_days$dateInYear, linetype = "dashed", linewidth = .25, color = "gray") +
geom_point(data = weather %>% filter(High == RecordHigh),
aes(x = dateInYear, y = RecordHigh),
shape = 25, fill = "black", size = 2) +
geom_text(data = weather %>% filter(High == RecordHigh),
aes(x = dateInYear, y = RecordHigh + 5, label = RecordHigh),
size = 2, vjust = 0, color = "black",
check_overlap = FALSE) +
theme_classic()+
theme(axis.line.x = element_blank(),
axis.ticks.x = element_blank()) +
scale_x_continuous(breaks = seq(15, 365, by = 30), labels = month.abb) +
scale_y_continuous(breaks = c(0,40,80,120)) +
expand_limits(y=c(-20, ceiling(130))) +
labs(title = "Temperature",
x = " ",
y = " ") +
theme(plot.title = element_text(face = "bold"))
precip <- weather %>%
ggplot(aes(x = dateInYear)) +
geom_vline(xintercept = last_days$dateInYear, color = "gray", linewidth = .25) +
geom_ribbon(aes(ymax = CulmPrec, ymin = 0, group = Month), fill = "#ebeae2") +
geom_line(aes(y = CulmPrec), color = "#32a3d8", linewidth = 0.3) +
geom_point(data = weather %>% filter(RecordP == TRUE),
aes(x = dateInYear, y = CulmPrec),
shape = 25, fill = "black", size = 1) +
geom_text(data = month_CulmPrec,
aes(x = dateInYear, y = CulmPrec + 0.5, label = round(CulmPrec, 2)),
size = 2, vjust = 0, color = "black") +
theme_classic() +
theme(axis.line.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
plot.title = element_text(face = "bold")) +
scale_y_continuous(breaks = c(4,8),
expand = c(0.35, 0)) +
labs(title = "Precipitation",
x = " ",
y = " ")
SFO_weather_2011 <- egg::ggarrange(temp, precip, nrow = 2, widths = c(10,10), heights = c(3,1))
annotate_figure(SFO_weather_2011, top = text_grob("SFO Weather in 2011"))
#SFO_weather_2011 <-
egg::ggarrange(temp, precip, nrow = 2, widths = c(10,10), heights = c(3,1))
annotate_figure(SFO_weather_2011, top = text_grob("SFO Weather in 2011"))
SFO_weather_2011 <- egg::ggarrange(temp, precip, nrow = 2, widths = c(10,10), heights = c(3,1))
SFO_weather_2011 <- annotate_figure(SFO_weather_2011, top = text_grob("SFO Weather in 2011"))
draft <- egg::ggarrange(temp, precip, nrow = 2, widths = c(10,10), heights = c(3,1))
SFO_weather_2011 <- annotate_figure(draft, top = text_grob("SFO Weather in 2011"))
draft <- egg::ggarrange(temp, precip, nrow = 2, widths = c(10,10), heights = c(3,1))
SFO_weather_2011 <- annotate_figure(draft, top = text_grob("SFO Weather in 2011"))
SFO_weather_2011
ggsave("SFO_weather_2011.png", SFO_weather_2011)
library(patchwork)
library(sf)
library(tidyverse)
library(tidycensus)
census2020 <- tidycensus::get_acs(
year = 2020,
state = "MN",
geography = "tract",
variables = c("B01003_001", "B19013_001", "B23006_023", "B25058_001", "B25107_001", "B25003_001", "B25003_002", "B25003_003", "B25077_001", "B08303_001"),
output = "wide",
geometry = TRUE
) %>%
filter(word(NAME, 4) %in% c("Ramsey")) %>%
mutate(
tract = word(NAME, 3),
tract = str_remove(tract, ","),
county = word(NAME, 4)
) %>%
select(-NAME) %>%
rename(
"population" = "B01003_001E",
"medianIncome" = "B19013_001E",
"bachelors" = "B23006_023E",
"medContractRent" = "B25058_001E",
"tenureTotal" = "B25003_001E",
"tenureOwned" = "B25003_002E",
"tenureRented" = "B25003_003E",
"medianHomeValue"= "B25077_001E",
"meanCommuteTime" = "B08303_001E"
) %>%
select(-contains("_"))
crashes <- read_csv("https://mac-stat.github.io/data/Crash.csv") %>%
filter(!is.na(Latitude), !is.na(Longitude))
roads <- sf::st_read("Data/tl_2019_27_prisecroads/tl_2019_27_prisecroads.shp")
library(patchwork)
library(sf)
library(tidyverse)
library(tidycensus)
census2020 <- tidycensus::get_acs(
year = 2020,
state = "MN",
geography = "tract",
variables = c("B01003_001", "B19013_001", "B23006_023", "B25058_001", "B25107_001", "B25003_001", "B25003_002", "B25003_003", "B25077_001", "B08303_001"),
output = "wide",
geometry = TRUE
) %>%
filter(word(NAME, 4) %in% c("Ramsey")) %>%
mutate(
tract = word(NAME, 3),
tract = str_remove(tract, ","),
county = word(NAME, 4)
) %>%
select(-NAME) %>%
rename(
"population" = "B01003_001E",
"medianIncome" = "B19013_001E",
"bachelors" = "B23006_023E",
"medContractRent" = "B25058_001E",
"tenureTotal" = "B25003_001E",
"tenureOwned" = "B25003_002E",
"tenureRented" = "B25003_003E",
"medianHomeValue"= "B25077_001E",
"meanCommuteTime" = "B08303_001E"
) %>%
select(-contains("_"))
crashes <- read_csv("https://mac-stat.github.io/data/Crash.csv") %>%
filter(!is.na(Latitude), !is.na(Longitude))
roads <- sf::st_read("Data/tl_2019_27_prisecroads/tl_2019_27_prisecroads.shp")
roads_transformed <- roads %>% st_transform(crs = st_crs(census2020))
# Check CRS of roads and transform if necessary
st_crs(roads_transformed)
crashes <- st_as_sf(crashes, coords = c("Longitude", "Latitude"), crs = "NAD83")
st_crs(census2020)
st_crs(crashes)
stPaul <- st_bbox(crashes)
roads_sub <- st_crop(roads, stPaul)
census2020_sub <- st_crop(census2020, stPaul)
crashes_ped_bike <- crashes %>%
filter(Crash_Type %in% c("Pedestrian", "Bicycle"))
crashes_per_tract <- st_join(crashes_ped_bike,census2020_sub) %>%
st_drop_geometry() %>% # removes geometry - makes the following calculation more efficient
filter(!is.na(Accident_Datetime)) %>%
count(tract)
crashes_per_tract
crashes_per_tract_geo <- left_join(census2020_sub, crashes_per_tract, by = "tract") %>%
filter(n > 0) %>%
st_as_sf()
colnames(crashes_per_tract_geo)
ggplot() +
geom_sf(data = crashes_per_tract_geo, aes(fill = n), color = "white", size = 0.1) +
geom_sf(data = roads_sub, color = "grey", size = 0.3) +
scale_fill_gradientn(colors = viridis::viridis(5), name = "Crashes") +
theme_minimal()
ggplot()+
geom_sf(data = census2020_sub, aes(fill = medianIncome, geometry = geometry), color = "white")+
geom_sf(data = roads_sub, color = "grey")+
geom_sf(data = crashes, color = "red", alpha = 0.5)+
scale_fill_gradientn(colors = viridis::viridis(5), name = "Median Income") +
theme_minimal()
ggplot(crashes_per_tract_geo, aes(x = medianIncome, y = n))+
geom_point()+
geom_smooth(method = "lm", se = FALSE)+
labs(title = "Median Income vs Crashes",
x = "Median Income", y = "Number of crashes")
most_crashes <-  crashes_per_tract_geo %>%
arrange(desc(n)) %>%
head(10)
least_crashes <- crashes_per_tract_geo %>%
arrange(n) %>%
head(15)
ggplot(most_crashes, aes(x = n, y = reorder(tract, n), fill = tract))+
geom_col()+
labs(title = "Crashes per tract",
subtitle = "The 10 tracts with the highest number of crashes.",
x = "Number of crashes",
y = "Tract")+
theme_minimal()
ggplot(least_crashes, aes(x = n, y = reorder(tract, n), fill = tract))+
geom_col()+
labs(title = "Crashes per tract",
subtitle = "The 10 tracts with the lowest number of crashes.",
x = "Number of crashes",
y = "Tract")+
theme_minimal()
ggsave("Crashes Ramsey.png", crashes)
crashes_map <- ggplot()+
geom_sf(data = census2020_sub, aes(fill = medianIncome, geometry = geometry), color = "white")+
geom_sf(data = roads_sub, color = "grey")+
geom_sf(data = crashes, color = "red", alpha = 0.5)+
scale_fill_gradientn(colors = viridis::viridis(5), name = "Median Income") +
theme_minimal()
ggplot(crashes_per_tract_geo, aes(x = medianIncome, y = n))+
geom_point()+
geom_smooth(method = "lm", se = FALSE)+
labs(title = "Median Income vs Crashes",
x = "Median Income", y = "Number of crashes")
most_crashes <-  crashes_per_tract_geo %>%
arrange(desc(n)) %>%
head(10)
least_crashes <- crashes_per_tract_geo %>%
arrange(n) %>%
head(15)
ggplot(most_crashes, aes(x = n, y = reorder(tract, n), fill = tract))+
geom_col()+
labs(title = "Crashes per tract",
subtitle = "The 10 tracts with the highest number of crashes.",
x = "Number of crashes",
y = "Tract")+
theme_minimal()
ggplot(least_crashes, aes(x = n, y = reorder(tract, n), fill = tract))+
geom_col()+
labs(title = "Crashes per tract",
subtitle = "The 10 tracts with the lowest number of crashes.",
x = "Number of crashes",
y = "Tract")+
theme_minimal()
ggsave("Crashes Ramsey.png", crashes)
ggsave("Crashes Ramsey.png", crashes_map)
tuesdata <- tidytuesdayR::tt_load('2022-08-09')
library(tidyverse)
library(ggplot2)
tuesdata <- tidytuesdayR::tt_load('2022-08-09')
wheels <- tuesdata$wheels
View(wheels)
dim(wheels)
library(dplyr)
library(ggplot2)
ferris_counts <- wheels %>%
count(country, name = "n")
ferris_counts <- wheels %>%
count(country, name = "n")
wheels_per_country <- ggplot(ferris_counts, aes(x = reorder(country, -n), y = n, fill = country)) +
geom_bar(stat = "identity") +
labs(title = "Number of Ferris Wheels per Country",
x = "Country",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
guides(fill = "none")
wheels_per_country
ferris_counts <- wheels %>%
count(country, name = "n")
wheels_per_country <- ggplot(ferris_counts, aes(x = reorder(country, -n), y = n, fill = country)) +
geom_bar(stat = "identity") +
labs(title = "Number of Ferris Wheels per Country",
x = "Country",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
wheels_per_country
ferris_counts <- wheels %>%
count(country, name = "n")
wheels_per_country <- ggplot(ferris_counts, aes(x = reorder(country, -n), y = n, fill = country)) +
geom_bar(stat = "identity") +
labs(title = "Number of Ferris Wheels per Country",
x = "Country",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
guide(fill = "none")
ferris_counts <- wheels %>%
count(country, name = "n")
wheels_per_country <- ggplot(ferris_counts, aes(x = reorder(country, -n), y = n, fill = country)) +
geom_bar(stat = "identity") +
labs(title = "Number of Ferris Wheels per Country",
x = "Country",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
guides(fill = "none")
wheels_per_country
ferris_counts <- wheels %>%
count(country, name = "n") %>%
mutate(color_group = ifelse(n == 1, "single", country))
wheels_per_country <- ggplot(ferris_counts, aes(x = reorder(country, -n), y = n, fill = country)) +
geom_bar(stat = "identity") +
labs(title = "Number of Ferris Wheels per Country",
x = "Country",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
guides(fill = "none")
wheels_per_country
ferris_counts <- wheels %>%
count(country, name = "n") %>%
mutate(color_group = ifelse(n == 1, "single", country))
wheels_per_country <- ggplot(ferris_counts, aes(x = reorder(country, -n), y = n, fill = country)) +
geom_bar(stat = "identity") +
labs(title = "Number of Ferris Wheels per Country",
x = "Country",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_fill_manual(
values = c("single" = "gray70"),
breaks = NULL  # remove "single" from legend
)
wheels_per_country
ferris_counts <- wheels %>%
count(country, name = "n") %>%
mutate(color_group = ifelse(n == 1, "single", country))
wheels_per_country <- ggplot(ferris_counts, aes(x = reorder(country, -n), y = n, fill = country)) +
geom_bar(stat = "identity") +
labs(title = "Number of Ferris Wheels per Country",
x = "Country",
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
guides(fill = "none")
wheels_per_country
ggsave("TT_stateFair.jpg", plot = wheels_per_country)
